{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a4355d-7c47-4958-a110-b298c22faecb",
   "metadata": {},
   "source": [
    "# Descripción del Caso\n",
    "\n",
    "Este documento describe un análisis de datos enfocado en la detección de fraudes utilizando diversos algoritmos de clasificación. El objetivo principal es identificar correctamente las instancias fraudulentas en un conjunto de datos y evaluar el rendimiento de diferentes modelos de clasificación para este propósito. A lo largo del documento, se abordarán distintas tareas que guiarán el análisis, desde la comprensión básica del conjunto de datos hasta la optimización de modelos mediante la búsqueda de hiperparámetros.\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "1. **Importación y Análisis Inicial del Conjunto de Datos:**\n",
    "   - Importar los datos desde un archivo CSV y determinar el porcentaje de observaciones que representan instancias de fraude.\n",
    "\n",
    "2. **Entrenamiento de Modelos de Clasificación:**\n",
    "   - Entrenar un clasificador dummy para establecer una línea base de comparación en términos de precisión y recall.\n",
    "   - Evaluar un clasificador de Máquinas de Soporte Vectorial (SVC) y calcular su precisión, recall, y precisión.\n",
    "\n",
    "3. **Análisis de Matrices de Confusión:**\n",
    "   - Utilizar un clasificador SVC con parámetros específicos para obtener una matriz de confusión bajo un umbral definido.\n",
    "\n",
    "4. **Curvas de Precisión-Recall y ROC:**\n",
    "   - Entrenar un clasificador de regresión logística y generar curvas de precisión-recall y ROC para evaluar el rendimiento en diferentes umbrales.\n",
    "   - Extraer métricas específicas de recall y tasa de verdaderos positivos para valores dados de precisión y tasa de falsos positivos.\n",
    "\n",
    "5. **Optimización de Modelos:**\n",
    "   - Realizar una búsqueda de hiperparámetros para un clasificador de regresión logística utilizando validación cruzada, maximizando el recall como métrica de rendimiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bf3709-f535-45c8-ba35-7171591687be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e895ca-8825-4d0f-8ecc-90274a674134",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Import the data from `assets/fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "*This function should return a float between 0 and 1.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ab65ac-27db-4ab2-9134-009eda854838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016410823768035772\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def answer_one():\n",
    "    df = pd.read_csv('assets/fraud_data.csv')\n",
    "    # Calcular el porcentaje de instancias de fraude\n",
    "    fraud_percentage = df['Class'].mean()\n",
    "    return fraud_percentage\n",
    "\n",
    "# Llamada a la función para ver el resultado\n",
    "print(answer_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a091c5dc-dd50-4202-8012-a148bd3d226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('assets/fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01439d3-624c-4f4f-815f-ec95d58d4756",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf598ab-758e-4126-9495-7d709c21e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9852507374631269, 0.0)\n"
     ]
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "    # Negative class (0) is most frequent\n",
    "    dummy_majority = DummyClassifier()\n",
    "    dummy_majority.fit(X_train, y_train)\n",
    "\n",
    "    # Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
    "    y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "\n",
    "    recall = recall_score(y_test, y_dummy_predictions, average='binary')\n",
    "    \n",
    "    # Accuracy_score function does not accept an average parameter\n",
    "    score = dummy_majority.score(X_test, y_test)\n",
    "    \n",
    "    return (score, recall)\n",
    "\n",
    "result = answer_two()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493aea0-1688-4591-9f13-5e1328936724",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
    "\n",
    "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58b0c963-f583-4c99-af17-21f5570264bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9901659496004918, 0.3673469387755102, 0.9473684210526315)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    from sklearn.metrics import recall_score, precision_score\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # Your code here\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    recall_score = recall_score(y_test, predictions)\n",
    "    precision_score = precision_score(y_test, predictions)\n",
    "    \n",
    "    return (score, recall_score, precision_score) # Return your answer\n",
    "\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be78b6d-aa8c-4cc3-ba12-394549cf8fa2",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
    "\n",
    "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fda6e96-4aaa-4ec8-a395-c69cba285297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6380   30]\n",
      " [  14   84]]\n"
     ]
    }
   ],
   "source": [
    "def answer_four():\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    svc_classifier = SVC(C=1e9, gamma=1e-07)\n",
    "    svc_classifier.fit(X_train, y_train)\n",
    "    decision_scores = svc_classifier.decision_function(X_test)\n",
    "    \n",
    "    threshold = -220\n",
    "    y_pred_thresholded = (decision_scores > threshold).astype(int)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_thresholded)\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "result = answer_four()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8fdd15-abd2-45ff-a510-195a628b2900",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train. This classifier should use the parameter solver='liblinear'.\n",
    "\n",
    "For the logisitic regression classifier, compute the scores using decision_function() or with predict_proba(), then create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "Note: When getting the ROC curve and finding the records where the FPR entry is closest to 0.16, take the corresponding TPRs. As there are two such records where the FPR is close to 0.16, take the higher TPR of these two records.\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a667e73a-8b70-49ed-b6ef-6700e01870e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.825, 0.95)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def answer_five():\n",
    "    # Cargo datos y separo etiquetas\n",
    "    df = pd.read_csv('assets/fraud_data.csv')\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # Divido en entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Entreno clasificador\n",
    "    lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "    # Obtengo las puntuaciones\n",
    "    y_scores_lr = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculo curva recall-precision\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_scores_lr)\n",
    "\n",
    "    # Encuentro el índice más cercano al valor de precisión deseado\n",
    "    desired_precision = 0.75\n",
    "    closest_precision_index = np.argmin(np.abs(precision - desired_precision))\n",
    "    approximate_recall = recall[closest_precision_index]\n",
    "\n",
    "    # Calculo la curva ROC\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_scores_lr)\n",
    "\n",
    "    # Encuentro el índice del FPR más cercano a 0.16\n",
    "    desired_fpr = 0.16\n",
    "    closest_fpr_indices = np.where(np.abs(fpr_lr - desired_fpr) == np.min(np.abs(fpr_lr - desired_fpr)))[0]\n",
    "    true_positive_rate = np.max(tpr_lr[closest_fpr_indices])\n",
    "\n",
    "    # Retorno el resultado como tuple\n",
    "    return approximate_recall, true_positive_rate\n",
    "\n",
    "# Llamo a la función\n",
    "result = answer_five()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d22fb-0395-4a32-a915-34eb8aec0aef",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation. (Suggest to use `solver='liblinear'`, more explanation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html))\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10]`\n",
    "\n",
    "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
    "\n",
    "|      \t| `l1` \t| `l2` \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| **`0.01`** \t|    ?\t|   ? \t|\n",
    "| **`0.1`**  \t|    ?\t|   ? \t|\n",
    "| **`1`**    \t|    ?\t|   ? \t|\n",
    "| **`10`**   \t|    ?\t|   ? \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "*This function should return a 4 by 2 numpy array with 8 floats.* \n",
    "\n",
    "*Note: do not return a DataFrame, just the values denoted by `?` in a numpy array.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "036fbf1d-d486-4c54-8311-1dc21d0a867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64728682 0.75581395]\n",
      " [0.79844961 0.81007752]\n",
      " [0.80620155 0.81007752]\n",
      " [0.80620155 0.81007752]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Carga de datos\n",
    "df = pd.read_csv('assets/fraud_data.csv')\n",
    "\n",
    "# Dividir en características (X) y etiquetas (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "def answer_six():\n",
    "    # Configurar el clasificador y los valores del grid\n",
    "    clf = LogisticRegression(solver='liblinear')\n",
    "    grid_values = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "    # Realizar la búsqueda en grid\n",
    "    grid_search = GridSearchCV(clf, param_grid=grid_values, scoring='recall', cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Extraer los resultados de la búsqueda\n",
    "    cv_result = grid_search.cv_results_\n",
    "    mean_test_score = cv_result['mean_test_score']\n",
    "\n",
    "    # Redimensionar los resultados a la forma requerida\n",
    "    result = np.array(mean_test_score).reshape(4, 2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Llamada a la función\n",
    "results_array = answer_six()\n",
    "print(results_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3392a1a8-3f18-491c-b57b-e48ace0f23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_Heatmap(scores):\n",
    "    get_ipython().magic('matplotlib notebook')\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
    "    plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1d025-9f58-48b9-ac72-c5d16cf6548b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
